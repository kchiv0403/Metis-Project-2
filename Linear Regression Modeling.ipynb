{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('/home/kchiv/kchiv/metis/metisgh/sf19_ds15/combined_article_metrics.pkl')\n",
    "\n",
    "df.loc[df['num_times_cited'] == 0, 'num_times_cited'] = 1\n",
    "df.loc[df['num_authors'] == 0, 'num_authors'] = 3\n",
    "df.loc[df['num_institutions'] == 0, 'num_institutions'] = 1\n",
    "df.loc[df['altmetric'] == 0, 'altmetric'] = 1\n",
    "df.loc[df['mean_i10_index'] == 0, 'mean_i10_index'] = 1\n",
    "\n",
    "\n",
    "y = np.log(df['altmetric'])\n",
    "df['num_times_cited_log'] = np.log(df['num_times_cited'])\n",
    "df['num_authors_log'] = np.log(df['num_authors'])\n",
    "df['mean_h_index_log'] = np.log(df['mean_h_index'])\n",
    "df['mean_i10_index_log'] = np.log(df['mean_i10_index'])\n",
    "\n",
    "\n",
    "drop_cols = ['altmetric','fig_count', 'top50','top100', 'num_times_cited', \n",
    "             'other', 'num_institutions', 'num_authors', 'mean_h_index',\n",
    "           'abstract_length', 'mean_i10_index','page_length', 'title_length', 'ref_cnt']\n",
    "\n",
    "df = df.drop(columns = drop_cols)\n",
    "X =df\n",
    "\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=71) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores: \n",
      " [0.5382291995178371, 0.5761023902365623, 0.43630232349250697, 0.570647743537464, 0.5531210103486601] \n",
      "\n",
      "Ridge scores: \n",
      " [0.5373331702543613, 0.5737514386093089, 0.43836710408002655, 0.5704865131623713, 0.5545780502799703] \n",
      "\n",
      "Lasso scores: \n",
      " [0.5417129718398761, 0.5730429586053811, 0.4362869659267191, 0.5710949742864683, 0.5545239390302655] \n",
      "\n",
      "Elastic scores: \n",
      " [0.5417129718398761, 0.5730429586053811, 0.4362869659267191, 0.5710949742864683, 0.5545239390302655] \n",
      "\n",
      "Poly scores: \n",
      " [0.43100333333479074, 0.09824073015194258, 0.46473224227209786, 0.5606097217246047, 0.5342620486021648] \n",
      "\n",
      "Simple mean cv r^2: 0.535 +- 0.051\n",
      "Ridge mean cv r^2: 0.535 +- 0.050\n",
      "Lasso mean cv r^2: 0.535 +- 0.051\n",
      "Elastic mean cv r^2: 0.535 +- 0.051\n",
      "Poly mean cv r^2: 0.418 +- 0.166\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s, cv_lasso_r2s, cv_elastic_r2s, cv_poly_r2s = [], [], [], [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    lm_reg = Ridge(alpha=10)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #lasso\n",
    "    lasso = Lasso(alpha = 0.01)\n",
    "\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    cv_lasso_r2s.append(lasso.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #Elastic Net CV\n",
    "    elastic = ElasticNet(alpha = 10, l1_ratio = 0.8)\n",
    "\n",
    "    elastic.fit(X_train_scaled, y_train)\n",
    "    cv_elastic_r2s.append(elastic.score(X_val_scaled, y_val))\n",
    "    \n",
    "    \n",
    "    #polynomial regression\n",
    "    lm_poly = LinearRegression()\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    X_poly = poly.fit_transform(X_train)\n",
    "    X_val = poly.transform(X_val)\n",
    "\n",
    "    lm_poly.fit(X_poly, y_train)\n",
    "#     y_pred = lm_poly.predict(X_poly)\n",
    "    \n",
    "#     cv_poly_r2s.append(r2_score(y_train, y_pred))\n",
    "    cv_poly_r2s.append(lm_poly.score(X_val, y_val))\n",
    "    \n",
    "\n",
    "\n",
    "print('Simple regression scores: \\n', cv_lm_r2s, '\\n')\n",
    "print('Ridge scores: \\n', cv_lm_reg_r2s, '\\n')\n",
    "print('Lasso scores: \\n', cv_lasso_r2s, '\\n')\n",
    "print('Elastic scores: \\n', cv_lasso_r2s, '\\n')\n",
    "print('Poly scores: \\n', cv_poly_r2s, '\\n')\n",
    "\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')\n",
    "print(f'Lasso mean cv r^2: {np.mean(cv_lasso_r2s):.3f} +- {np.std(cv_lasso_r2s):.3f}')\n",
    "print(f'Elastic mean cv r^2: {np.mean(cv_lasso_r2s):.3f} +- {np.std(cv_lasso_r2s):.3f}')\n",
    "print(f'Poly mean cv r^2: {np.mean(cv_poly_r2s):.3f} +- {np.std(cv_poly_r2s):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mean_author_citations', -0.08356828968527669),\n",
       " ('top20', 0.10435534234536795),\n",
       " ('year', -1.2979305086075599),\n",
       " ('num_times_cited_log', 0.6657202617547507),\n",
       " ('num_authors_log', 0.1821045899317982),\n",
       " ('mean_h_index_log', 0.09004325562517684),\n",
       " ('mean_i10_index_log', -0.07635046707442826)]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.columns, lm_reg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5203541123090603"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=71) #hold out 20% of the data for final testing\n",
    "\n",
    "lm_reg = Ridge(alpha=100)\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg.fit(X_scaled, y_train)\n",
    "lm_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.431003332534747"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=71) #hold out 20% of the data for final testing\n",
    "\n",
    "lm_poly = LinearRegression()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "    \n",
    "X_poly = poly.fit_transform(X_train)\n",
    "X_test_scaled = poly.transform(X_test)\n",
    "\n",
    "lm_poly.fit(X_poly, y_train)\n",
    "lm_poly.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('num_times_cited', -8.823107637090529e-09),\n",
       " ('mean_author_citations', -0.9527752720440794),\n",
       " ('mean_h_index', -0.00029623380030888564),\n",
       " ('mean_i10_index', 2.6079724062394383),\n",
       " ('num_authors', 0.002467310054922143),\n",
       " ('top20', 1.2627747026995295),\n",
       " ('year', -0.09979510871796438)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.columns, lm_poly.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0., -0.])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with non-generated values of only 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with non-generated values of only 80\n",
    "df=pd.read_pickle('/home/kchiv/kchiv/metis/metisgh/sf19_ds15/real_article_metrics.pkl')\n",
    "\n",
    "df.loc[df['num_times_cited'] == 0, 'num_times_cited'] = 1\n",
    "df.loc[df['num_authors'] == 0, 'num_authors'] = 3\n",
    "df.loc[df['num_institutions'] == 0, 'num_institutions'] = 1\n",
    "df.loc[df['altmetric'] == 0, 'altmetric'] = 1\n",
    "df.loc[df['mean_i10_index'] == 0, 'mean_i10_index'] = 1\n",
    "\n",
    "\n",
    "y = np.log(df['altmetric'])\n",
    "df['num_times_cited'] = np.log(df['num_times_cited'])\n",
    "df['num_authors'] = np.log(df['num_authors'])\n",
    "df['mean_h_index'] = np.log(df['mean_h_index'])\n",
    "\n",
    "drop_cols = ['altmetric','fig_count', 'top50','top100',\n",
    "             'other', 'num_institutions', 'mean_author_citations',\n",
    "           'abstract_length', 'page_length', 'title_length', 'mean_i10_index', 'ref_cnt']\n",
    "\n",
    "\n",
    "df = df.drop(columns = drop_cols)\n",
    "X =df\n",
    "\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=71) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores: \n",
      " [0.5369828241547616, 0.7824714777838894, 0.687874097145421, 0.5249063710583584, -1.3968190570662569, 0.5956617315852406, 0.6703236521698307, 0.8620037642849794, 0.5706170397159102, 0.31780999464352067] \n",
      "\n",
      "Ridge scores: \n",
      " [0.22639733542114837, 0.48992127503558613, 0.5753365001440827, 0.43725952092094733, -1.3565261031713542, 0.3456363127430241, 0.3545155689498865, 0.502638583101522, 0.23568511136024653, 0.3486507827840071] \n",
      "\n",
      "Poly scores: \n",
      " [-0.2500903328907249, 0.15471686378608984, 0.2514500940688431, -0.4081691807119967, -1.0622028077341468, 0.314345891675308, 0.268083916704126, 0.7993817615311783, 0.46588925218236926, 0.39309978711449256] \n",
      "\n",
      "Simple mean cv r^2: 0.415 +- 0.621\n",
      "Ridge mean cv r^2: 0.216 +- 0.535\n",
      "Poly mean cv r^2: 0.093 +- 0.504\n"
     ]
    }
   ],
   "source": [
    "f = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s, cv_poly_r2s = [], [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    lm_reg = Ridge(alpha=100)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "    \n",
    "    \n",
    "    #polynomial regression\n",
    "    lm_poly = LinearRegression()\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    X_poly = poly.fit_transform(X_train)\n",
    "    X_val = poly.transform(X_val)\n",
    "\n",
    "    lm_poly.fit(X_poly, y_train)\n",
    "#     y_pred = lm_poly.predict(X_poly)\n",
    "    \n",
    "#     cv_poly_r2s.append(r2_score(y_train, y_pred))\n",
    "    cv_poly_r2s.append(lm_poly.score(X_val, y_val))\n",
    "\n",
    "\n",
    "print('Simple regression scores: \\n', cv_lm_r2s, '\\n')\n",
    "print('Ridge scores: \\n', cv_lm_reg_r2s, '\\n')\n",
    "print('Poly scores: \\n', cv_poly_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')\n",
    "print(f'Poly mean cv r^2: {np.mean(cv_poly_r2s):.3f} +- {np.std(cv_poly_r2s):.3f}')\n",
    "\n",
    "#the non-generated values perform terribly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
