{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages <a name=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"table\"></a>\n",
    "1. [Import Packages](#import)\n",
    "2. [Transforming Data](#transform)\n",
    "3. [Standardization](#scale)\n",
    "4. [Feature Engineering](#feature)\n",
    "5. [Cross-Validation](#val)\n",
    "    1. [Regular](#reg)\n",
    "    2. [LASSO](#lasso)\n",
    "    3. [Ridge](#ridge)\n",
    "5. [Results](#results)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data <a name=\"transform\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"altmetric\" should be log-transformed since it is non-negative and count-like<br>\n",
    "\"num_times_cited\", \"num_institutions\", and \"num_authors\" could be log-transformed for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>altmetric</th>\n",
       "      <th>num_times_cited</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>page_length</th>\n",
       "      <th>fig_count</th>\n",
       "      <th>ref_cnt</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>top100</th>\n",
       "      <th>other</th>\n",
       "      <th>num_institutions</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>551</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>647</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_length  altmetric  num_times_cited  abstract_length  page_length  \\\n",
       "0            12          0              112               68            5   \n",
       "1             8          6              112               59            5   \n",
       "2            10         24              551               62            5   \n",
       "3             9         33              647               51            7   \n",
       "4             7          1              473               57            5   \n",
       "\n",
       "   fig_count  ref_cnt  num_authors  top100  other  num_institutions  year  \n",
       "0          6       47            9       1      1                 2    10  \n",
       "1          8       42            5       1      1                 5    10  \n",
       "2          7       38           33       0      1                 9    10  \n",
       "3         10       52           14       0      1                12    10  \n",
       "4         10       49            6       1      1                 2    10  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "combined = pd.read_pickle('combined_article_metrics.pkl') \n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.146</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.139</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   21.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>2.77e-37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:14:18</td>     <th>  Log-Likelihood:    </th> <td> -9261.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>1.855e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>1.860e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>  251.3673</td> <td>   46.189</td> <td>    5.442</td> <td> 0.000</td> <td>  160.750</td> <td>  341.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>    6.6093</td> <td>    5.471</td> <td>    1.208</td> <td> 0.227</td> <td>   -4.125</td> <td>   17.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.1441</td> <td>    0.026</td> <td>    5.559</td> <td> 0.000</td> <td>    0.093</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>   -0.4140</td> <td>    0.302</td> <td>   -1.370</td> <td> 0.171</td> <td>   -1.007</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -2.4681</td> <td>   13.284</td> <td>   -0.186</td> <td> 0.853</td> <td>  -28.530</td> <td>   23.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>   -4.8306</td> <td>    4.410</td> <td>   -1.095</td> <td> 0.274</td> <td>  -13.482</td> <td>    3.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -1.0856</td> <td>    0.598</td> <td>   -1.815</td> <td> 0.070</td> <td>   -2.259</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    1.1146</td> <td>    0.466</td> <td>    2.392</td> <td> 0.017</td> <td>    0.201</td> <td>    2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>   -3.7508</td> <td>   21.209</td> <td>   -0.177</td> <td> 0.860</td> <td>  -45.359</td> <td>   37.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>  251.3673</td> <td>   46.189</td> <td>    5.442</td> <td> 0.000</td> <td>  160.750</td> <td>  341.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>   -0.3923</td> <td>    0.789</td> <td>   -0.497</td> <td> 0.619</td> <td>   -1.940</td> <td>    1.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>  -55.6676</td> <td>    4.183</td> <td>  -13.309</td> <td> 0.000</td> <td>  -63.874</td> <td>  -47.462</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1399.958</td> <th>  Durbin-Watson:     </th> <td>   1.988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>99336.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 5.506</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>44.975</td>  <th>  Cond. No.          </th> <td>2.58e+19</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.146\n",
       "Model:                            OLS   Adj. R-squared:                  0.139\n",
       "Method:                 Least Squares   F-statistic:                     21.48\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):           2.77e-37\n",
       "Time:                        00:14:18   Log-Likelihood:                -9261.9\n",
       "No. Observations:                1266   AIC:                         1.855e+04\n",
       "Df Residuals:                    1255   BIC:                         1.860e+04\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const              251.3673     46.189      5.442      0.000     160.750     341.984\n",
       "title_length         6.6093      5.471      1.208      0.227      -4.125      17.344\n",
       "num_times_cited      0.1441      0.026      5.559      0.000       0.093       0.195\n",
       "abstract_length     -0.4140      0.302     -1.370      0.171      -1.007       0.179\n",
       "page_length         -2.4681     13.284     -0.186      0.853     -28.530      23.594\n",
       "fig_count           -4.8306      4.410     -1.095      0.274     -13.482       3.821\n",
       "ref_cnt             -1.0856      0.598     -1.815      0.070      -2.259       0.088\n",
       "num_authors          1.1146      0.466      2.392      0.017       0.201       2.029\n",
       "top100              -3.7508     21.209     -0.177      0.860     -45.359      37.857\n",
       "other              251.3673     46.189      5.442      0.000     160.750     341.984\n",
       "num_institutions    -0.3923      0.789     -0.497      0.619      -1.940       1.156\n",
       "year               -55.6676      4.183    -13.309      0.000     -63.874     -47.462\n",
       "==============================================================================\n",
       "Omnibus:                     1399.958   Durbin-Watson:                   1.988\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            99336.114\n",
       "Skew:                           5.506   Prob(JB):                         0.00\n",
       "Kurtosis:                      44.975   Cond. No.                     2.58e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original model\n",
    "df = combined.copy()\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results improve from a log transform of the dependent variable. <br>\n",
    "However, the test score is worse than the train score due to multi-collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: -0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.495</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   125.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>1.64e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:14:31</td>     <th>  Log-Likelihood:    </th> <td> -1880.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3784.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3840.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    3.2333</td> <td>    0.136</td> <td>   23.830</td> <td> 0.000</td> <td>    2.967</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0119</td> <td>    0.016</td> <td>   -0.739</td> <td> 0.460</td> <td>   -0.043</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.0010</td> <td> 7.62e-05</td> <td>   12.481</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>   -0.0029</td> <td>    0.001</td> <td>   -3.291</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0149</td> <td>    0.039</td> <td>   -0.383</td> <td> 0.702</td> <td>   -0.091</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>   -0.0095</td> <td>    0.013</td> <td>   -0.737</td> <td> 0.461</td> <td>   -0.035</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0025</td> <td>    0.002</td> <td>   -1.409</td> <td> 0.159</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0075</td> <td>    0.001</td> <td>    5.515</td> <td> 0.000</td> <td>    0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.1546</td> <td>    0.062</td> <td>    2.482</td> <td> 0.013</td> <td>    0.032</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    3.2333</td> <td>    0.136</td> <td>   23.830</td> <td> 0.000</td> <td>    2.967</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>   -0.0050</td> <td>    0.002</td> <td>   -2.173</td> <td> 0.030</td> <td>   -0.010</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -0.3916</td> <td>    0.012</td> <td>  -31.868</td> <td> 0.000</td> <td>   -0.416</td> <td>   -0.367</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.630</td> <th>  Durbin-Watson:     </th> <td>   1.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.022</td> <th>  Jarque-Bera (JB):  </th> <td>   7.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.155</td> <th>  Prob(JB):          </th> <td>  0.0203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.228</td> <th>  Cond. No.          </th> <td>2.58e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.499\n",
       "Model:                            OLS   Adj. R-squared:                  0.495\n",
       "Method:                 Least Squares   F-statistic:                     125.0\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):          1.64e-180\n",
       "Time:                        00:14:31   Log-Likelihood:                -1880.9\n",
       "No. Observations:                1266   AIC:                             3784.\n",
       "Df Residuals:                    1255   BIC:                             3840.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                3.2333      0.136     23.830      0.000       2.967       3.500\n",
       "title_length        -0.0119      0.016     -0.739      0.460      -0.043       0.020\n",
       "num_times_cited      0.0010   7.62e-05     12.481      0.000       0.001       0.001\n",
       "abstract_length     -0.0029      0.001     -3.291      0.001      -0.005      -0.001\n",
       "page_length         -0.0149      0.039     -0.383      0.702      -0.091       0.062\n",
       "fig_count           -0.0095      0.013     -0.737      0.461      -0.035       0.016\n",
       "ref_cnt             -0.0025      0.002     -1.409      0.159      -0.006       0.001\n",
       "num_authors          0.0075      0.001      5.515      0.000       0.005       0.010\n",
       "top100               0.1546      0.062      2.482      0.013       0.032       0.277\n",
       "other                3.2333      0.136     23.830      0.000       2.967       3.500\n",
       "num_institutions    -0.0050      0.002     -2.173      0.030      -0.010      -0.000\n",
       "year                -0.3916      0.012    -31.868      0.000      -0.416      -0.367\n",
       "==============================================================================\n",
       "Omnibus:                        7.630   Durbin-Watson:                   1.913\n",
       "Prob(Omnibus):                  0.022   Jarque-Bera (JB):                7.796\n",
       "Skew:                           0.155   Prob(JB):                       0.0203\n",
       "Kurtosis:                       3.228   Cond. No.                     2.58e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model\n",
    "\n",
    "df = combined.copy()\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(np.log(y_train+1), X_train)\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit = model.fit() \n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results further improved from taking the log transform of 'num_times_cited', 'num_institutions', and 'num_authors'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>6.61e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:15:16</td>     <th>  Log-Likelihood:    </th> <td> -1788.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3600.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3656.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    1.9018</td> <td>    0.133</td> <td>   14.332</td> <td> 0.000</td> <td>    1.642</td> <td>    2.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0062</td> <td>    0.015</td> <td>   -0.413</td> <td> 0.680</td> <td>   -0.036</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.5800</td> <td>    0.035</td> <td>   16.694</td> <td> 0.000</td> <td>    0.512</td> <td>    0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>    0.0008</td> <td>    0.001</td> <td>    0.888</td> <td> 0.375</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0112</td> <td>    0.035</td> <td>   -0.325</td> <td> 0.745</td> <td>   -0.079</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>    0.0029</td> <td>    0.012</td> <td>    0.243</td> <td> 0.808</td> <td>   -0.021</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0052</td> <td>    0.002</td> <td>   -3.158</td> <td> 0.002</td> <td>   -0.008</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0911</td> <td>    0.038</td> <td>    2.408</td> <td> 0.016</td> <td>    0.017</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.0397</td> <td>    0.061</td> <td>    0.651</td> <td> 0.515</td> <td>   -0.080</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    1.9018</td> <td>    0.133</td> <td>   14.332</td> <td> 0.000</td> <td>    1.642</td> <td>    2.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>    0.1326</td> <td>    0.041</td> <td>    3.199</td> <td> 0.001</td> <td>    0.051</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -0.4780</td> <td>    0.014</td> <td>  -33.767</td> <td> 0.000</td> <td>   -0.506</td> <td>   -0.450</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.130</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.246</td> <th>  Prob(JB):          </th> <td>2.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>1.95e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.27e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.567\n",
       "Model:                            OLS   Adj. R-squared:                  0.563\n",
       "Method:                 Least Squares   F-statistic:                     164.2\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):          6.61e-220\n",
       "Time:                        00:15:16   Log-Likelihood:                -1788.9\n",
       "No. Observations:                1266   AIC:                             3600.\n",
       "Df Residuals:                    1255   BIC:                             3656.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                1.9018      0.133     14.332      0.000       1.642       2.162\n",
       "title_length        -0.0062      0.015     -0.413      0.680      -0.036       0.023\n",
       "num_times_cited      0.5800      0.035     16.694      0.000       0.512       0.648\n",
       "abstract_length      0.0008      0.001      0.888      0.375      -0.001       0.002\n",
       "page_length         -0.0112      0.035     -0.325      0.745      -0.079       0.057\n",
       "fig_count            0.0029      0.012      0.243      0.808      -0.021       0.027\n",
       "ref_cnt             -0.0052      0.002     -3.158      0.002      -0.008      -0.002\n",
       "num_authors          0.0911      0.038      2.408      0.016       0.017       0.165\n",
       "top100               0.0397      0.061      0.651      0.515      -0.080       0.159\n",
       "other                1.9018      0.133     14.332      0.000       1.642       2.162\n",
       "num_institutions     0.1326      0.041      3.199      0.001       0.051       0.214\n",
       "year                -0.4780      0.014    -33.767      0.000      -0.506      -0.450\n",
       "==============================================================================\n",
       "Omnibus:                       19.130   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.220\n",
       "Skew:                           0.246   Prob(JB):                     2.47e-05\n",
       "Kurtosis:                       3.400   Cond. No.                     1.95e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.27e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "\n",
    "fit = model.fit() \n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization <a name=\"scale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only scale the non-categorical independent variables and combine it back with our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>6.61e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:15:28</td>     <th>  Log-Likelihood:    </th> <td> -1788.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3600.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3656.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    2.1778</td> <td>    0.020</td> <td>  109.215</td> <td> 0.000</td> <td>    2.139</td> <td>    2.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0117</td> <td>    0.028</td> <td>   -0.413</td> <td> 0.680</td> <td>   -0.067</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.7255</td> <td>    0.043</td> <td>   16.694</td> <td> 0.000</td> <td>    0.640</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>    0.0312</td> <td>    0.035</td> <td>    0.888</td> <td> 0.375</td> <td>   -0.038</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0101</td> <td>    0.031</td> <td>   -0.325</td> <td> 0.745</td> <td>   -0.071</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>    0.0082</td> <td>    0.034</td> <td>    0.243</td> <td> 0.808</td> <td>   -0.058</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0928</td> <td>    0.029</td> <td>   -3.158</td> <td> 0.002</td> <td>   -0.150</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0927</td> <td>    0.038</td> <td>    2.408</td> <td> 0.016</td> <td>    0.017</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>    0.1384</td> <td>    0.043</td> <td>    3.199</td> <td> 0.001</td> <td>    0.054</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -1.3636</td> <td>    0.040</td> <td>  -33.767</td> <td> 0.000</td> <td>   -1.443</td> <td>   -1.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.0397</td> <td>    0.061</td> <td>    0.651</td> <td> 0.515</td> <td>   -0.080</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    2.1778</td> <td>    0.020</td> <td>  109.215</td> <td> 0.000</td> <td>    2.139</td> <td>    2.217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.130</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.246</td> <th>  Prob(JB):          </th> <td>2.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>4.23e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.61e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.567\n",
       "Model:                            OLS   Adj. R-squared:                  0.563\n",
       "Method:                 Least Squares   F-statistic:                     164.2\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):          6.61e-220\n",
       "Time:                        00:15:28   Log-Likelihood:                -1788.9\n",
       "No. Observations:                1266   AIC:                             3600.\n",
       "Df Residuals:                    1255   BIC:                             3656.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                2.1778      0.020    109.215      0.000       2.139       2.217\n",
       "title_length        -0.0117      0.028     -0.413      0.680      -0.067       0.044\n",
       "num_times_cited      0.7255      0.043     16.694      0.000       0.640       0.811\n",
       "abstract_length      0.0312      0.035      0.888      0.375      -0.038       0.100\n",
       "page_length         -0.0101      0.031     -0.325      0.745      -0.071       0.051\n",
       "fig_count            0.0082      0.034      0.243      0.808      -0.058       0.075\n",
       "ref_cnt             -0.0928      0.029     -3.158      0.002      -0.150      -0.035\n",
       "num_authors          0.0927      0.038      2.408      0.016       0.017       0.168\n",
       "num_institutions     0.1384      0.043      3.199      0.001       0.054       0.223\n",
       "year                -1.3636      0.040    -33.767      0.000      -1.443      -1.284\n",
       "top100               0.0397      0.061      0.651      0.515      -0.080       0.159\n",
       "other                2.1778      0.020    109.215      0.000       2.139       2.217\n",
       "==============================================================================\n",
       "Omnibus:                       19.130   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.220\n",
       "Skew:                           0.246   Prob(JB):                     2.47e-05\n",
       "Kurtosis:                       3.400   Cond. No.                     4.23e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.61e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "        \n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#we need to reset the index due to how we scale later\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "#split train and test sets into categorical and non-categorical data\n",
    "non_cat_train, cat_train = X_train.drop(columns = ['top100', 'other']), X_train[['top100', 'other']]\n",
    "non_cat_test, cat_test = X_test.drop(columns = ['top100', 'other']), X_test[['top100', 'other']]\n",
    "\n",
    "non_cat_cols = non_cat_train.columns\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#only fit and transform on train set\n",
    "non_cat_train = scaler.fit_transform(non_cat_train)\n",
    "non_cat_train = pd.DataFrame(non_cat_train, columns = non_cat_cols)\n",
    "\n",
    "#use same scale to scale test set\n",
    "non_cat_test = scaler.transform(non_cat_test)\n",
    "non_cat_test = pd.DataFrame(non_cat_test, columns = non_cat_cols)\n",
    "\n",
    "#combine categorical and non-categorical data together into train and test\n",
    "X_train = pd.concat([non_cat_train, cat_train], axis = 1)\n",
    "X_test =  pd.concat([non_cat_test, cat_test], axis = 1)\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, \"top100\" had multi-collinearity with the intercept due it having 0 variance. <br>\n",
    "Removing that fixed the issues. <br>\n",
    "Features with low statistical significance i.e. high p-values were also removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.566</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.564</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   328.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>1.71e-225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:15:38</td>     <th>  Log-Likelihood:    </th> <td> -1789.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3592.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1260</td>      <th>  BIC:               </th> <td>   3623.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.3740</td> <td>    0.028</td> <td>  156.060</td> <td> 0.000</td> <td>    4.319</td> <td>    4.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7059</td> <td>    0.040</td> <td>   17.785</td> <td> 0.000</td> <td>    0.628</td> <td>    0.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0944</td> <td>    0.029</td> <td>   -3.259</td> <td> 0.001</td> <td>   -0.151</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0907</td> <td>    0.038</td> <td>    2.384</td> <td> 0.017</td> <td>    0.016</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1501</td> <td>    0.040</td> <td>    3.795</td> <td> 0.000</td> <td>    0.073</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.3621</td> <td>    0.040</td> <td>  -34.135</td> <td> 0.000</td> <td>   -1.440</td> <td>   -1.284</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.981</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  19.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.242</td> <th>  Prob(JB):          </th> <td>5.37e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.373</td> <th>  Cond. No.          </th> <td>    2.59</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.566\n",
       "Model:                            OLS   Adj. R-squared:                  0.564\n",
       "Method:                 Least Squares   F-statistic:                     328.8\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):          1.71e-225\n",
       "Time:                        00:15:38   Log-Likelihood:                -1789.9\n",
       "No. Observations:                1266   AIC:                             3592.\n",
       "Df Residuals:                    1260   BIC:                             3623.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.3740      0.028    156.060      0.000       4.319       4.429\n",
       "x1             0.7059      0.040     17.785      0.000       0.628       0.784\n",
       "x2            -0.0944      0.029     -3.259      0.001      -0.151      -0.038\n",
       "x3             0.0907      0.038      2.384      0.017       0.016       0.165\n",
       "x4             0.1501      0.040      3.795      0.000       0.073       0.228\n",
       "x5            -1.3621      0.040    -34.135      0.000      -1.440      -1.284\n",
       "==============================================================================\n",
       "Omnibus:                       17.981   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.666\n",
       "Skew:                           0.242   Prob(JB):                     5.37e-05\n",
       "Kurtosis:                       3.373   Cond. No.                         2.59\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with fewer scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a name=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try some feature engineering as well with PolynomialFeatures. <br>\n",
    "The results offer a modest improvement, but not enough to justify its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.583</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.577</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   87.20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>5.59e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:16:07</td>     <th>  Log-Likelihood:    </th> <td> -1764.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3570.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1245</td>      <th>  BIC:               </th> <td>   3678.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.1837</td> <td>    0.025</td> <td>   87.218</td> <td> 0.000</td> <td>    2.135</td> <td>    2.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.1837</td> <td>    0.025</td> <td>   87.218</td> <td> 0.000</td> <td>    2.135</td> <td>    2.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.7218</td> <td>    0.045</td> <td>   15.907</td> <td> 0.000</td> <td>    0.633</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1889</td> <td>    0.040</td> <td>   -4.771</td> <td> 0.000</td> <td>   -0.267</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0570</td> <td>    0.055</td> <td>    1.029</td> <td> 0.303</td> <td>   -0.052</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.1699</td> <td>    0.055</td> <td>    3.067</td> <td> 0.002</td> <td>    0.061</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.3532</td> <td>    0.045</td> <td>  -30.388</td> <td> 0.000</td> <td>   -1.441</td> <td>   -1.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0873</td> <td>    0.036</td> <td>    2.393</td> <td> 0.017</td> <td>    0.016</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.1192</td> <td>    0.050</td> <td>    2.393</td> <td> 0.017</td> <td>    0.021</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0903</td> <td>    0.057</td> <td>    1.581</td> <td> 0.114</td> <td>   -0.022</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1799</td> <td>    0.055</td> <td>   -3.248</td> <td> 0.001</td> <td>   -0.289</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0230</td> <td>    0.067</td> <td>    0.341</td> <td> 0.733</td> <td>   -0.109</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0009</td> <td>    0.005</td> <td>   -0.158</td> <td> 0.875</td> <td>   -0.012</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0319</td> <td>    0.048</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.126</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0255</td> <td>    0.046</td> <td>    0.556</td> <td> 0.578</td> <td>   -0.064</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.1983</td> <td>    0.056</td> <td>   -3.550</td> <td> 0.000</td> <td>   -0.308</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0567</td> <td>    0.039</td> <td>    1.446</td> <td> 0.148</td> <td>   -0.020</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0488</td> <td>    0.040</td> <td>   -1.213</td> <td> 0.225</td> <td>   -0.128</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0946</td> <td>    0.060</td> <td>   -1.583</td> <td> 0.114</td> <td>   -0.212</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0045</td> <td>    0.039</td> <td>   -0.115</td> <td> 0.908</td> <td>   -0.080</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.1310</td> <td>    0.059</td> <td>    2.203</td> <td> 0.028</td> <td>    0.014</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.1178</td> <td>    0.047</td> <td>   -2.512</td> <td> 0.012</td> <td>   -0.210</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.831</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  14.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.190</td> <th>  Prob(JB):          </th> <td>0.000887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.350</td> <th>  Cond. No.          </th> <td>1.29e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.5e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.583\n",
       "Model:                            OLS   Adj. R-squared:                  0.577\n",
       "Method:                 Least Squares   F-statistic:                     87.20\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):          5.59e-220\n",
       "Time:                        00:16:07   Log-Likelihood:                -1764.1\n",
       "No. Observations:                1266   AIC:                             3570.\n",
       "Df Residuals:                    1245   BIC:                             3678.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.1837      0.025     87.218      0.000       2.135       2.233\n",
       "x1             2.1837      0.025     87.218      0.000       2.135       2.233\n",
       "x2             0.7218      0.045     15.907      0.000       0.633       0.811\n",
       "x3            -0.1889      0.040     -4.771      0.000      -0.267      -0.111\n",
       "x4             0.0570      0.055      1.029      0.303      -0.052       0.166\n",
       "x5             0.1699      0.055      3.067      0.002       0.061       0.279\n",
       "x6            -1.3532      0.045    -30.388      0.000      -1.441      -1.266\n",
       "x7             0.0873      0.036      2.393      0.017       0.016       0.159\n",
       "x8             0.1192      0.050      2.393      0.017       0.021       0.217\n",
       "x9             0.0903      0.057      1.581      0.114      -0.022       0.202\n",
       "x10           -0.1799      0.055     -3.248      0.001      -0.289      -0.071\n",
       "x11            0.0230      0.067      0.341      0.733      -0.109       0.155\n",
       "x12           -0.0009      0.005     -0.158      0.875      -0.012       0.010\n",
       "x13           -0.0319      0.048     -0.667      0.505      -0.126       0.062\n",
       "x14            0.0255      0.046      0.556      0.578      -0.064       0.115\n",
       "x15           -0.1983      0.056     -3.550      0.000      -0.308      -0.089\n",
       "x16            0.0567      0.039      1.446      0.148      -0.020       0.134\n",
       "x17           -0.0488      0.040     -1.213      0.225      -0.128       0.030\n",
       "x18           -0.0946      0.060     -1.583      0.114      -0.212       0.023\n",
       "x19           -0.0045      0.039     -0.115      0.908      -0.080       0.072\n",
       "x20            0.1310      0.059      2.203      0.028       0.014       0.248\n",
       "x21           -0.1178      0.047     -2.512      0.012      -0.210      -0.026\n",
       "==============================================================================\n",
       "Omnibus:                       12.831   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.055\n",
       "Skew:                           0.190   Prob(JB):                     0.000887\n",
       "Kurtosis:                       3.350   Cond. No.                     1.29e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.5e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "#scale data and generate new features\n",
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit() \n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation <a name=\"val\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular  <a name=\"reg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Scores Across Folds:\n",
      "[0.53749217 0.61061453 0.53484424 0.61640161 0.5053464 ]\n",
      "\n",
      "Simple Mean CV R^2: 0.561 +- 0.044\n",
      "\n",
      "R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(lm, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print('R^2 Scores Across Folds:')\n",
    "print(scores)\n",
    "print(f'\\nSimple Mean CV R^2: {np.mean(scores):.3f} +- {np.std(scores):.3f}')\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "print('\\nR^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO  <a name=\"lasso\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value for LASSO: 0.01\n",
      "\n",
      "Beta Coefficients for LASSO:\n",
      "[('num_times_cited', 0.6776115674476927),\n",
      " ('ref_cnt', -0.0793647647705093),\n",
      " ('num_authors', 0.08623889484343929),\n",
      " ('num_institutions', 0.1523097073200145),\n",
      " ('year', -1.3309224723401527)]\n",
      "\n",
      "LASSO R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "#This is the best alpha value it found - not far from the value\n",
    "#selected using simple validation\n",
    "print('Best alpha value for LASSO: ' + str(lasso_model.alpha_))\n",
    "\n",
    "#These are the (standardized) coefficients found\n",
    "#when it refit using that best alpha\n",
    "print('\\nBeta Coefficients for LASSO:')\n",
    "pp.pprint(list(zip(X.columns, lasso_model.coef_)))\n",
    "\n",
    "#Make predictions on the test set using the new model\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "print('\\nLASSO R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge  <a name=\"ridge\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best alpha value for Ridge: 5.415871378079471\n",
      "\n",
      "Beta Coefficients for Ridge:\n",
      "[('num_times_cited', 0.6923908603009206),\n",
      " ('ref_cnt', -0.09191536316201651),\n",
      " ('num_authors', 0.09188107559845608),\n",
      " ('num_institutions', 0.15353755321840368),\n",
      " ('year', -1.346590455614971)]\n",
      "\n",
      "Ridge R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphavec, cv=5)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "#This is the best alpha value it found - not far from the value\n",
    "#selected using simple validation\n",
    "print('\\nBest alpha value for Ridge: ' + str(ridge_model.alpha_))\n",
    "\n",
    "#These are the (standardized) coefficients found\n",
    "#when it refit using that best alpha\n",
    "print('\\nBeta Coefficients for Ridge:')\n",
    "pp.pprint(list(zip(X.columns, ridge_model.coef_)))\n",
    "\n",
    "#Make predictions on the test set using the new model\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "print('\\nRidge R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, OLS still does as well as LASSO and Ridge. <br>\n",
    "It is time to interpret the beta-coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the beta coefficients, we first divide each feature's beta coefficient value by each feature's standard deviation. <br>\n",
    "Next, we must exponential transform our beta coefficients since we applied a log transform to the dependent variable. <br>\n",
    "\n",
    "The results indicate that: <br>\n",
    "- for every additional time an article is cited, an article increases its Altmetric score by 1.75 <br>\n",
    "- for every additional reference used, an article increases its Altmetric score by 0.99 <br>\n",
    "- for every additional author that worked on the paper, an article increases its Altmetric score by 1.09 <br>\n",
    "- for every additional institution involved, an article increases its Altmetric score by 1.15 <br>\n",
    "- for every additional year since publication, an article increases its Altmetric score by 0.62 <br>\n",
    "\n",
    "The Altmetric score uses the number of citiations as a factor, so its helpful to note that it is the most important factor <br>\n",
    "Obviously, some recommendations are more feasible than others. <br>\n",
    "Using additional references and involving more people is one way to increase article impact, but it may minimize impact from personal contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('num_times_cited', 1.7583307847949132),\n",
      " ('ref_cnt', 0.9947693533855977),\n",
      " ('num_authors', 1.0932833862356837),\n",
      " ('num_institutions', 1.1546592615471494),\n",
      " ('year', 0.620330061464877)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(X.columns, np.exp(lm.coef_/scaler.scale_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
