{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages <a name=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"table\"></a>\n",
    "1. [Import Packages](#import)\n",
    "2. [Transforming Data](#transform)\n",
    "3. [Standardization](#scale)\n",
    "4. [Feature Engineering](#feature)\n",
    "5. [Cross-Validation](#val)\n",
    "    1. [Regular](#reg)\n",
    "    2. [LASSO](#lasso)\n",
    "    3. [Ridge](#ridge)\n",
    "5. [Results](#results)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transforming Data <a name=\"transform\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"altmetric\" should be log-transformed since it is non-negative and count-like<br>\n",
    "\"num_times_cited\", \"num_institutions\", and \"num_authors\" could be log-transformed for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>altmetric</th>\n",
       "      <th>num_times_cited</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>page_length</th>\n",
       "      <th>fig_count</th>\n",
       "      <th>ref_cnt</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>top100</th>\n",
       "      <th>other</th>\n",
       "      <th>num_institutions</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>551</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>647</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_length  altmetric  num_times_cited  abstract_length  page_length  \\\n",
       "0            12          0              112               68            5   \n",
       "1             8          6              112               59            5   \n",
       "2            10         24              551               62            5   \n",
       "3             9         33              647               51            7   \n",
       "4             7          1              473               57            5   \n",
       "\n",
       "   fig_count  ref_cnt  num_authors  top100  other  num_institutions  year  \n",
       "0          6       47            9       1      1                 2    10  \n",
       "1          8       42            5       1      1                 5    10  \n",
       "2          7       38           33       0      1                 9    10  \n",
       "3         10       52           14       0      1                12    10  \n",
       "4         10       49            6       1      1                 2    10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "combined = pd.read_pickle('./data/combined_article_metrics.pkl') \n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.146</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.139</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   21.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>2.77e-37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:54:52</td>     <th>  Log-Likelihood:    </th> <td> -9261.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>1.855e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>1.860e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>  251.3673</td> <td>   46.189</td> <td>    5.442</td> <td> 0.000</td> <td>  160.750</td> <td>  341.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>    6.6093</td> <td>    5.471</td> <td>    1.208</td> <td> 0.227</td> <td>   -4.125</td> <td>   17.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.1441</td> <td>    0.026</td> <td>    5.559</td> <td> 0.000</td> <td>    0.093</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>   -0.4140</td> <td>    0.302</td> <td>   -1.370</td> <td> 0.171</td> <td>   -1.007</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -2.4681</td> <td>   13.284</td> <td>   -0.186</td> <td> 0.853</td> <td>  -28.530</td> <td>   23.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>   -4.8306</td> <td>    4.410</td> <td>   -1.095</td> <td> 0.274</td> <td>  -13.482</td> <td>    3.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -1.0856</td> <td>    0.598</td> <td>   -1.815</td> <td> 0.070</td> <td>   -2.259</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    1.1146</td> <td>    0.466</td> <td>    2.392</td> <td> 0.017</td> <td>    0.201</td> <td>    2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>   -3.7508</td> <td>   21.209</td> <td>   -0.177</td> <td> 0.860</td> <td>  -45.359</td> <td>   37.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>  251.3673</td> <td>   46.189</td> <td>    5.442</td> <td> 0.000</td> <td>  160.750</td> <td>  341.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>   -0.3923</td> <td>    0.789</td> <td>   -0.497</td> <td> 0.619</td> <td>   -1.940</td> <td>    1.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>  -55.6676</td> <td>    4.183</td> <td>  -13.309</td> <td> 0.000</td> <td>  -63.874</td> <td>  -47.462</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1399.958</td> <th>  Durbin-Watson:     </th> <td>   1.988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>99336.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 5.506</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>44.975</td>  <th>  Cond. No.          </th> <td>2.58e+19</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.146\n",
       "Model:                            OLS   Adj. R-squared:                  0.139\n",
       "Method:                 Least Squares   F-statistic:                     21.48\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):           2.77e-37\n",
       "Time:                        13:54:52   Log-Likelihood:                -9261.9\n",
       "No. Observations:                1266   AIC:                         1.855e+04\n",
       "Df Residuals:                    1255   BIC:                         1.860e+04\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const              251.3673     46.189      5.442      0.000     160.750     341.984\n",
       "title_length         6.6093      5.471      1.208      0.227      -4.125      17.344\n",
       "num_times_cited      0.1441      0.026      5.559      0.000       0.093       0.195\n",
       "abstract_length     -0.4140      0.302     -1.370      0.171      -1.007       0.179\n",
       "page_length         -2.4681     13.284     -0.186      0.853     -28.530      23.594\n",
       "fig_count           -4.8306      4.410     -1.095      0.274     -13.482       3.821\n",
       "ref_cnt             -1.0856      0.598     -1.815      0.070      -2.259       0.088\n",
       "num_authors          1.1146      0.466      2.392      0.017       0.201       2.029\n",
       "top100              -3.7508     21.209     -0.177      0.860     -45.359      37.857\n",
       "other              251.3673     46.189      5.442      0.000     160.750     341.984\n",
       "num_institutions    -0.3923      0.789     -0.497      0.619      -1.940       1.156\n",
       "year               -55.6676      4.183    -13.309      0.000     -63.874     -47.462\n",
       "==============================================================================\n",
       "Omnibus:                     1399.958   Durbin-Watson:                   1.988\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            99336.114\n",
       "Skew:                           5.506   Prob(JB):                         0.00\n",
       "Kurtosis:                      44.975   Cond. No.                     2.58e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original model\n",
    "df = combined.copy()\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results improve from a log transform of the dependent variable. <br>\n",
    "However, the test score is worse than the train score due to multi-collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.495</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   125.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.64e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:54:58</td>     <th>  Log-Likelihood:    </th> <td> -1880.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3784.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3840.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    3.2333</td> <td>    0.136</td> <td>   23.830</td> <td> 0.000</td> <td>    2.967</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0119</td> <td>    0.016</td> <td>   -0.739</td> <td> 0.460</td> <td>   -0.043</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.0010</td> <td> 7.62e-05</td> <td>   12.481</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>   -0.0029</td> <td>    0.001</td> <td>   -3.291</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0149</td> <td>    0.039</td> <td>   -0.383</td> <td> 0.702</td> <td>   -0.091</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>   -0.0095</td> <td>    0.013</td> <td>   -0.737</td> <td> 0.461</td> <td>   -0.035</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0025</td> <td>    0.002</td> <td>   -1.409</td> <td> 0.159</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0075</td> <td>    0.001</td> <td>    5.515</td> <td> 0.000</td> <td>    0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.1546</td> <td>    0.062</td> <td>    2.482</td> <td> 0.013</td> <td>    0.032</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    3.2333</td> <td>    0.136</td> <td>   23.830</td> <td> 0.000</td> <td>    2.967</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>   -0.0050</td> <td>    0.002</td> <td>   -2.173</td> <td> 0.030</td> <td>   -0.010</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -0.3916</td> <td>    0.012</td> <td>  -31.868</td> <td> 0.000</td> <td>   -0.416</td> <td>   -0.367</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.630</td> <th>  Durbin-Watson:     </th> <td>   1.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.022</td> <th>  Jarque-Bera (JB):  </th> <td>   7.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.155</td> <th>  Prob(JB):          </th> <td>  0.0203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.228</td> <th>  Cond. No.          </th> <td>2.58e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.499\n",
       "Model:                            OLS   Adj. R-squared:                  0.495\n",
       "Method:                 Least Squares   F-statistic:                     125.0\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):          1.64e-180\n",
       "Time:                        13:54:58   Log-Likelihood:                -1880.9\n",
       "No. Observations:                1266   AIC:                             3784.\n",
       "Df Residuals:                    1255   BIC:                             3840.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                3.2333      0.136     23.830      0.000       2.967       3.500\n",
       "title_length        -0.0119      0.016     -0.739      0.460      -0.043       0.020\n",
       "num_times_cited      0.0010   7.62e-05     12.481      0.000       0.001       0.001\n",
       "abstract_length     -0.0029      0.001     -3.291      0.001      -0.005      -0.001\n",
       "page_length         -0.0149      0.039     -0.383      0.702      -0.091       0.062\n",
       "fig_count           -0.0095      0.013     -0.737      0.461      -0.035       0.016\n",
       "ref_cnt             -0.0025      0.002     -1.409      0.159      -0.006       0.001\n",
       "num_authors          0.0075      0.001      5.515      0.000       0.005       0.010\n",
       "top100               0.1546      0.062      2.482      0.013       0.032       0.277\n",
       "other                3.2333      0.136     23.830      0.000       2.967       3.500\n",
       "num_institutions    -0.0050      0.002     -2.173      0.030      -0.010      -0.000\n",
       "year                -0.3916      0.012    -31.868      0.000      -0.416      -0.367\n",
       "==============================================================================\n",
       "Omnibus:                        7.630   Durbin-Watson:                   1.913\n",
       "Prob(Omnibus):                  0.022   Jarque-Bera (JB):                7.796\n",
       "Skew:                           0.155   Prob(JB):                       0.0203\n",
       "Kurtosis:                       3.228   Cond. No.                     2.58e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.25e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model\n",
    "\n",
    "df = combined.copy()\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(np.log(y_train+1), X_train)\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit = model.fit() \n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results further improved from taking the log transform of 'num_times_cited', 'num_institutions', and 'num_authors'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>6.61e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:55:01</td>     <th>  Log-Likelihood:    </th> <td> -1788.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3600.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3656.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    1.9018</td> <td>    0.133</td> <td>   14.332</td> <td> 0.000</td> <td>    1.642</td> <td>    2.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0062</td> <td>    0.015</td> <td>   -0.413</td> <td> 0.680</td> <td>   -0.036</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.5800</td> <td>    0.035</td> <td>   16.694</td> <td> 0.000</td> <td>    0.512</td> <td>    0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>    0.0008</td> <td>    0.001</td> <td>    0.888</td> <td> 0.375</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0112</td> <td>    0.035</td> <td>   -0.325</td> <td> 0.745</td> <td>   -0.079</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>    0.0029</td> <td>    0.012</td> <td>    0.243</td> <td> 0.808</td> <td>   -0.021</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0052</td> <td>    0.002</td> <td>   -3.158</td> <td> 0.002</td> <td>   -0.008</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0911</td> <td>    0.038</td> <td>    2.408</td> <td> 0.016</td> <td>    0.017</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.0397</td> <td>    0.061</td> <td>    0.651</td> <td> 0.515</td> <td>   -0.080</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    1.9018</td> <td>    0.133</td> <td>   14.332</td> <td> 0.000</td> <td>    1.642</td> <td>    2.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>    0.1326</td> <td>    0.041</td> <td>    3.199</td> <td> 0.001</td> <td>    0.051</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -0.4780</td> <td>    0.014</td> <td>  -33.767</td> <td> 0.000</td> <td>   -0.506</td> <td>   -0.450</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.130</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.246</td> <th>  Prob(JB):          </th> <td>2.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>1.95e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.27e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.567\n",
       "Model:                            OLS   Adj. R-squared:                  0.563\n",
       "Method:                 Least Squares   F-statistic:                     164.2\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):          6.61e-220\n",
       "Time:                        13:55:01   Log-Likelihood:                -1788.9\n",
       "No. Observations:                1266   AIC:                             3600.\n",
       "Df Residuals:                    1255   BIC:                             3656.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                1.9018      0.133     14.332      0.000       1.642       2.162\n",
       "title_length        -0.0062      0.015     -0.413      0.680      -0.036       0.023\n",
       "num_times_cited      0.5800      0.035     16.694      0.000       0.512       0.648\n",
       "abstract_length      0.0008      0.001      0.888      0.375      -0.001       0.002\n",
       "page_length         -0.0112      0.035     -0.325      0.745      -0.079       0.057\n",
       "fig_count            0.0029      0.012      0.243      0.808      -0.021       0.027\n",
       "ref_cnt             -0.0052      0.002     -3.158      0.002      -0.008      -0.002\n",
       "num_authors          0.0911      0.038      2.408      0.016       0.017       0.165\n",
       "top100               0.0397      0.061      0.651      0.515      -0.080       0.159\n",
       "other                1.9018      0.133     14.332      0.000       1.642       2.162\n",
       "num_institutions     0.1326      0.041      3.199      0.001       0.051       0.214\n",
       "year                -0.4780      0.014    -33.767      0.000      -0.506      -0.450\n",
       "==============================================================================\n",
       "Omnibus:                       19.130   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.220\n",
       "Skew:                           0.246   Prob(JB):                     2.47e-05\n",
       "Kurtosis:                       3.400   Cond. No.                     1.95e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.27e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "X_train = sm.add_constant(X_train, has_constant='add') #something already has a variance of 0\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "\n",
    "fit = model.fit() \n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardization <a name=\"scale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only scale the non-categorical independent variables and combine it back with our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchiv/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>6.61e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:55:03</td>     <th>  Log-Likelihood:    </th> <td> -1788.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3600.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1255</td>      <th>  BIC:               </th> <td>   3656.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    2.1778</td> <td>    0.020</td> <td>  109.215</td> <td> 0.000</td> <td>    2.139</td> <td>    2.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top100</th>           <td>    0.0397</td> <td>    0.061</td> <td>    0.651</td> <td> 0.515</td> <td>   -0.080</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>other</th>            <td>    2.1778</td> <td>    0.020</td> <td>  109.215</td> <td> 0.000</td> <td>    2.139</td> <td>    2.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>     <td>   -0.0117</td> <td>    0.028</td> <td>   -0.413</td> <td> 0.680</td> <td>   -0.067</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_times_cited</th>  <td>    0.7255</td> <td>    0.043</td> <td>   16.694</td> <td> 0.000</td> <td>    0.640</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abstract_length</th>  <td>    0.0312</td> <td>    0.035</td> <td>    0.888</td> <td> 0.375</td> <td>   -0.038</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page_length</th>      <td>   -0.0101</td> <td>    0.031</td> <td>   -0.325</td> <td> 0.745</td> <td>   -0.071</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig_count</th>        <td>    0.0082</td> <td>    0.034</td> <td>    0.243</td> <td> 0.808</td> <td>   -0.058</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ref_cnt</th>          <td>   -0.0928</td> <td>    0.029</td> <td>   -3.158</td> <td> 0.002</td> <td>   -0.150</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_authors</th>      <td>    0.0927</td> <td>    0.038</td> <td>    2.408</td> <td> 0.016</td> <td>    0.017</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_institutions</th> <td>    0.1384</td> <td>    0.043</td> <td>    3.199</td> <td> 0.001</td> <td>    0.054</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -1.3636</td> <td>    0.040</td> <td>  -33.767</td> <td> 0.000</td> <td>   -1.443</td> <td>   -1.284</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.130</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.246</td> <th>  Prob(JB):          </th> <td>2.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>5.52e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.46e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.567\n",
       "Model:                            OLS   Adj. R-squared:                  0.563\n",
       "Method:                 Least Squares   F-statistic:                     164.2\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):          6.61e-220\n",
       "Time:                        13:55:03   Log-Likelihood:                -1788.9\n",
       "No. Observations:                1266   AIC:                             3600.\n",
       "Df Residuals:                    1255   BIC:                             3656.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                2.1778      0.020    109.215      0.000       2.139       2.217\n",
       "top100               0.0397      0.061      0.651      0.515      -0.080       0.159\n",
       "other                2.1778      0.020    109.215      0.000       2.139       2.217\n",
       "title_length        -0.0117      0.028     -0.413      0.680      -0.067       0.044\n",
       "num_times_cited      0.7255      0.043     16.694      0.000       0.640       0.811\n",
       "abstract_length      0.0312      0.035      0.888      0.375      -0.038       0.100\n",
       "page_length         -0.0101      0.031     -0.325      0.745      -0.071       0.051\n",
       "fig_count            0.0082      0.034      0.243      0.808      -0.058       0.075\n",
       "ref_cnt             -0.0928      0.029     -3.158      0.002      -0.150      -0.035\n",
       "num_authors          0.0927      0.038      2.408      0.016       0.017       0.168\n",
       "num_institutions     0.1384      0.043      3.199      0.001       0.054       0.223\n",
       "year                -1.3636      0.040    -33.767      0.000      -1.443      -1.284\n",
       "==============================================================================\n",
       "Omnibus:                       19.130   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.220\n",
       "Skew:                           0.246   Prob(JB):                     2.47e-05\n",
       "Kurtosis:                       3.400   Cond. No.                     5.52e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.46e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "        \n",
    "X, y = df.drop(columns = ['altmetric']), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "#scale only the non-categorical columns\n",
    "cat_cols = ['top100', 'other']\n",
    "scaled_cols = X_train.columns[~X_train.columns.isin(cat_cols)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#drop the columns to be scaled to make reassigning easier\n",
    "X_train, scaled_train_cols = X_train.drop(columns = scaled_cols), \\\n",
    "                                scaler.fit_transform(X_train[scaled_cols])\n",
    "\n",
    "X_test, scaled_test_cols = X_test.drop(columns = scaled_cols), \\\n",
    "                                scaler.transform(X_test[scaled_cols])\n",
    "\n",
    "#recreate the columns with the scaled values\n",
    "#while making sure to reassign at the correct index\n",
    "X_train[scaled_cols] = pd.DataFrame(scaled_train_cols,\n",
    "                                    index = X_train.index,\n",
    "                                    columns = scaled_cols)\n",
    "\n",
    "X_test[scaled_cols] = pd.DataFrame(scaled_test_cols,\n",
    "                                   index = X_test.index,\n",
    "                                   columns = scaled_cols)\n",
    "\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['const', 'top100', 'other'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[~X_train.columns.isin(scaled_cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, \"top100\" had multi-collinearity with the intercept due it having 0 variance. <br>\n",
    "Removing that fixed the issues. <br>\n",
    "Features with low statistical significance i.e. high p-values were also removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for Test: 0.53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.566</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.564</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   328.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.71e-225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:55:27</td>     <th>  Log-Likelihood:    </th> <td> -1789.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3592.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1260</td>      <th>  BIC:               </th> <td>   3623.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.3740</td> <td>    0.028</td> <td>  156.060</td> <td> 0.000</td> <td>    4.319</td> <td>    4.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7059</td> <td>    0.040</td> <td>   17.785</td> <td> 0.000</td> <td>    0.628</td> <td>    0.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0944</td> <td>    0.029</td> <td>   -3.259</td> <td> 0.001</td> <td>   -0.151</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0907</td> <td>    0.038</td> <td>    2.384</td> <td> 0.017</td> <td>    0.016</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1501</td> <td>    0.040</td> <td>    3.795</td> <td> 0.000</td> <td>    0.073</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.3621</td> <td>    0.040</td> <td>  -34.135</td> <td> 0.000</td> <td>   -1.440</td> <td>   -1.284</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.981</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  19.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.242</td> <th>  Prob(JB):          </th> <td>5.37e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.373</td> <th>  Cond. No.          </th> <td>    2.59</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.566\n",
       "Model:                            OLS   Adj. R-squared:                  0.564\n",
       "Method:                 Least Squares   F-statistic:                     328.8\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):          1.71e-225\n",
       "Time:                        13:55:27   Log-Likelihood:                -1789.9\n",
       "No. Observations:                1266   AIC:                             3592.\n",
       "Df Residuals:                    1260   BIC:                             3623.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.3740      0.028    156.060      0.000       4.319       4.429\n",
       "x1             0.7059      0.040     17.785      0.000       0.628       0.784\n",
       "x2            -0.0944      0.029     -3.259      0.001      -0.151      -0.038\n",
       "x3             0.0907      0.038      2.384      0.017       0.016       0.165\n",
       "x4             0.1501      0.040      3.795      0.000       0.073       0.228\n",
       "x5            -1.3621      0.040    -34.135      0.000      -1.440      -1.284\n",
       "==============================================================================\n",
       "Omnibus:                       17.981   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.666\n",
       "Skew:                           0.242   Prob(JB):                     5.37e-05\n",
       "Kurtosis:                       3.373   Cond. No.                         2.59\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log model with fewer scaled and log-transformed independent variables\n",
    "\n",
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit()\n",
    "\n",
    "X_test = sm.add_constant(X_test, has_constant='add') \n",
    "y_pred = fit.predict(X_test)\n",
    "print('R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering <a name=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try some feature engineering as well with PolynomialFeatures. <br>\n",
    "The results offer a modest improvement, but not enough to justify its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>altmetric</td>    <th>  R-squared:         </th> <td>   0.583</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.577</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   87.20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>5.59e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:55:30</td>     <th>  Log-Likelihood:    </th> <td> -1764.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1266</td>      <th>  AIC:               </th> <td>   3570.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1245</td>      <th>  BIC:               </th> <td>   3678.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.1837</td> <td>    0.025</td> <td>   87.218</td> <td> 0.000</td> <td>    2.135</td> <td>    2.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.1837</td> <td>    0.025</td> <td>   87.218</td> <td> 0.000</td> <td>    2.135</td> <td>    2.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.7218</td> <td>    0.045</td> <td>   15.907</td> <td> 0.000</td> <td>    0.633</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1889</td> <td>    0.040</td> <td>   -4.771</td> <td> 0.000</td> <td>   -0.267</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0570</td> <td>    0.055</td> <td>    1.029</td> <td> 0.303</td> <td>   -0.052</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.1699</td> <td>    0.055</td> <td>    3.067</td> <td> 0.002</td> <td>    0.061</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.3532</td> <td>    0.045</td> <td>  -30.388</td> <td> 0.000</td> <td>   -1.441</td> <td>   -1.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0873</td> <td>    0.036</td> <td>    2.393</td> <td> 0.017</td> <td>    0.016</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.1192</td> <td>    0.050</td> <td>    2.393</td> <td> 0.017</td> <td>    0.021</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0903</td> <td>    0.057</td> <td>    1.581</td> <td> 0.114</td> <td>   -0.022</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1799</td> <td>    0.055</td> <td>   -3.248</td> <td> 0.001</td> <td>   -0.289</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0230</td> <td>    0.067</td> <td>    0.341</td> <td> 0.733</td> <td>   -0.109</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0009</td> <td>    0.005</td> <td>   -0.158</td> <td> 0.875</td> <td>   -0.012</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0319</td> <td>    0.048</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.126</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0255</td> <td>    0.046</td> <td>    0.556</td> <td> 0.578</td> <td>   -0.064</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.1983</td> <td>    0.056</td> <td>   -3.550</td> <td> 0.000</td> <td>   -0.308</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0567</td> <td>    0.039</td> <td>    1.446</td> <td> 0.148</td> <td>   -0.020</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0488</td> <td>    0.040</td> <td>   -1.213</td> <td> 0.225</td> <td>   -0.128</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0946</td> <td>    0.060</td> <td>   -1.583</td> <td> 0.114</td> <td>   -0.212</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0045</td> <td>    0.039</td> <td>   -0.115</td> <td> 0.908</td> <td>   -0.080</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.1310</td> <td>    0.059</td> <td>    2.203</td> <td> 0.028</td> <td>    0.014</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.1178</td> <td>    0.047</td> <td>   -2.512</td> <td> 0.012</td> <td>   -0.210</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.831</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  14.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.190</td> <th>  Prob(JB):          </th> <td>0.000887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.350</td> <th>  Cond. No.          </th> <td>1.29e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.5e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              altmetric   R-squared:                       0.583\n",
       "Model:                            OLS   Adj. R-squared:                  0.577\n",
       "Method:                 Least Squares   F-statistic:                     87.20\n",
       "Date:                Mon, 09 Mar 2020   Prob (F-statistic):          5.59e-220\n",
       "Time:                        13:55:30   Log-Likelihood:                -1764.1\n",
       "No. Observations:                1266   AIC:                             3570.\n",
       "Df Residuals:                    1245   BIC:                             3678.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.1837      0.025     87.218      0.000       2.135       2.233\n",
       "x1             2.1837      0.025     87.218      0.000       2.135       2.233\n",
       "x2             0.7218      0.045     15.907      0.000       0.633       0.811\n",
       "x3            -0.1889      0.040     -4.771      0.000      -0.267      -0.111\n",
       "x4             0.0570      0.055      1.029      0.303      -0.052       0.166\n",
       "x5             0.1699      0.055      3.067      0.002       0.061       0.279\n",
       "x6            -1.3532      0.045    -30.388      0.000      -1.441      -1.266\n",
       "x7             0.0873      0.036      2.393      0.017       0.016       0.159\n",
       "x8             0.1192      0.050      2.393      0.017       0.021       0.217\n",
       "x9             0.0903      0.057      1.581      0.114      -0.022       0.202\n",
       "x10           -0.1799      0.055     -3.248      0.001      -0.289      -0.071\n",
       "x11            0.0230      0.067      0.341      0.733      -0.109       0.155\n",
       "x12           -0.0009      0.005     -0.158      0.875      -0.012       0.010\n",
       "x13           -0.0319      0.048     -0.667      0.505      -0.126       0.062\n",
       "x14            0.0255      0.046      0.556      0.578      -0.064       0.115\n",
       "x15           -0.1983      0.056     -3.550      0.000      -0.308      -0.089\n",
       "x16            0.0567      0.039      1.446      0.148      -0.020       0.134\n",
       "x17           -0.0488      0.040     -1.213      0.225      -0.128       0.030\n",
       "x18           -0.0946      0.060     -1.583      0.114      -0.212       0.023\n",
       "x19           -0.0045      0.039     -0.115      0.908      -0.080       0.072\n",
       "x20            0.1310      0.059      2.203      0.028       0.014       0.248\n",
       "x21           -0.1178      0.047     -2.512      0.012      -0.210      -0.026\n",
       "==============================================================================\n",
       "Omnibus:                       12.831   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.055\n",
       "Skew:                           0.190   Prob(JB):                     0.000887\n",
       "Kurtosis:                       3.350   Cond. No.                     1.29e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.5e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "#scale data and generate new features\n",
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "#something already has a variance of 0\n",
    "X_train = sm.add_constant(X_train, has_constant='add') \n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "fit = model.fit() \n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation <a name=\"val\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined.copy()\n",
    "log_cols = ['altmetric', 'num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col == 'altmetric':\n",
    "        df[col] = np.log(df[col] + 1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "drop_cols = ['altmetric','other', 'top100', 'title_length', \n",
    "             'abstract_length','page_length', 'fig_count']        \n",
    "        \n",
    "X, y = df.drop(columns = drop_cols), df['altmetric']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#only fit_transform on train set, transform on test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5A. Regular  <a name=\"reg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Scores Across Folds:\n",
      "[0.53749217 0.61061453 0.53484424 0.61640161 0.5053464 ]\n",
      "\n",
      "Simple Mean CV R^2: 0.561 +- 0.044\n",
      "\n",
      "R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(lm, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print('R^2 Scores Across Folds:')\n",
    "print(scores)\n",
    "print(f'\\nSimple Mean CV R^2: {np.mean(scores):.3f} +- {np.std(scores):.3f}')\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "print('\\nR^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5B. LASSO  <a name=\"lasso\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value for LASSO: 0.01\n",
      "\n",
      "Beta Coefficients for LASSO:\n",
      "[('num_times_cited', 0.6776115674476927),\n",
      " ('ref_cnt', -0.0793647647705093),\n",
      " ('num_authors', 0.08623889484343929),\n",
      " ('num_institutions', 0.1523097073200145),\n",
      " ('year', -1.3309224723401527)]\n",
      "\n",
      "R^2 Scores Across Folds:\n",
      "[0.53828039 0.60880223 0.53307737 0.61682156 0.50711864]\n",
      "\n",
      "Simple Mean CV R^2: 0.561 +- 0.044\n",
      "\n",
      "LASSO R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "#This is the best alpha value it found - not far from the value\n",
    "#selected using simple validation\n",
    "print('Best alpha value for LASSO: ' + str(lasso_model.alpha_))\n",
    "\n",
    "#These are the (standardized) coefficients found\n",
    "#when it refit using that best alpha\n",
    "print('\\nBeta Coefficients for LASSO:')\n",
    "pp.pprint(list(zip(X.columns, lasso_model.coef_)))\n",
    "\n",
    "lasso_model = Lasso(alpha = 0.01)\n",
    "\n",
    "scores = cross_val_score(lasso_model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print('\\nR^2 Scores Across Folds:')\n",
    "print(scores)\n",
    "print(f'\\nSimple Mean CV R^2: {np.mean(scores):.3f} +- {np.std(scores):.3f}')\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test set using the new model\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "print('\\nLASSO R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5C. Ridge  <a name=\"ridge\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best alpha value for Ridge: 5.415871378079471\n",
      "\n",
      "Beta Coefficients for Ridge:\n",
      "[('num_times_cited', 0.6923908603009206),\n",
      " ('ref_cnt', -0.09191536316201651),\n",
      " ('num_authors', 0.09188107559845608),\n",
      " ('num_institutions', 0.15353755321840368),\n",
      " ('year', -1.346590455614971)]\n",
      "\n",
      "R^2 Scores Across Folds:\n",
      "[0.53725617 0.60997323 0.53425082 0.61702043 0.50618867]\n",
      "\n",
      "Simple Mean CV R^2: 0.561 +- 0.044\n",
      "\n",
      "Ridge R^2 Score for Test: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphavec, cv=5)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "#This is the best alpha value it found - not far from the value\n",
    "#selected using simple validation\n",
    "print('\\nBest alpha value for Ridge: ' + str(ridge_model.alpha_))\n",
    "\n",
    "#These are the (standardized) coefficients found\n",
    "#when it refit using that best alpha\n",
    "print('\\nBeta Coefficients for Ridge:')\n",
    "pp.pprint(list(zip(X.columns, ridge_model.coef_)))\n",
    "\n",
    "ridge_model = Ridge(alpha = 5.14587)\n",
    "\n",
    "scores = cross_val_score(ridge_model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print('\\nR^2 Scores Across Folds:')\n",
    "print(scores)\n",
    "print(f'\\nSimple Mean CV R^2: {np.mean(scores):.3f} +- {np.std(scores):.3f}')\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions on the test set using the new model\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "print('\\nRidge R^2 Score for Test: ' + str(round(r2_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, OLS still does as well as LASSO and Ridge as seen by the plot. <br>\n",
    "There are no circles outside each box plot, indicating no outliers. <br>\n",
    "It is time to interpret the beta-coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAGHCAYAAABieS8lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5RkZX3u8e/jjOgAGkEGAwMKZgYxEsXQ4jVKjCBHEzAxUdCoLKOYy8RwcjTBnKhkXMlx6UnAHAgBDWq8gMYLjoYlgoq3iKFRRBkcbQaQmUEdGOQiIzd/54+9G4uyZ5hLv93VM9/PWrW697vf/dZbvavq2e+7d1WnqpAkqYUHzHYHJEnbL0NGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgymhVJjktS/e2AKdYfNrD+OdN0n/v17R23FdtelOSizahXA7e7k1yd5N1J9tmaPm/ifnZJ8r4kP+rv65TpbF+aLoaMZtutwMumKH95v24ueg/wVOAw4B+Bo4DPJlkwjffxZ8CxwOv6+zp5GtuWps20hEySpyb5apIvJDk7yQOno13tED4G/GGSTBb0b8YvBD46a73aNmuq6uKq+nJVnQr8JXAA8D+2teEkD+p/fSywtqr+vb+va6epXWlaTddI5lrg2VX1LGAVcPQ0tavt3/uARwHPGCj7XWAeGwmZJH+Y5JtJfprkhn7aaK+hOjsn+ZckNya5LclyYMopqyTPSvLZJLcm+UmS85McND0PD4BL+p+LB+7zCUmWJ7kpyYYkX0nyG0P9ek+S1f1B3H8l2QC8LUkBxwH7DkzNHdZv85gkH0/y477di5McOdTuSf02B/WP9Tbgw/26i5J8OcmRSS7r2/hGkicnmZ/kH5Jcn2R9379dhtr+uyRfT3Jzv28+l+QpQ3Ump0KPSnJqX29dkvcnedhQ3flJ/jrJin5/r0vy6SQHDtTZI8npSdYkuSPJd5Icv1V7StNuWkKmqtZW1YZ+8W7gZ9PRrnYI1wJf5L5TZi8HPg7cNly5f/N4H3Al8HvAicBzgS8k2XWg6hnAq4B/6uutBD44RXvPBz7b39cfAi8BHgJ8Kcm+2/jYJu3f//xxf5+/DvwXsDvwarpR243AhUkOGdr2l4BzgLPpRkIfpJseOx/4Qf/7U4GvJ9kb+DLwBGAp8KL+Pv8zyVSjqE8AX6CbzhucblsMvB14K/AHwIOA5cDpwF50AbcMeCnw5qE2F/VtvaCv9yPgi0keP8X9vwMour/5sv7v8I6hOucAfw+c17f5amBF3w+SPBT4CvB84KT+5yeB05P8+RT3qZlWVfd7A3ajezLcBtxO98bwR1PU2x/4b2CnjbTzDLoX183Aeronx5M2pw/etq8b3RtQ0b2hvRK4CXgw3ZvH3cDhdOc0CnhOv8084IfA54faekZf77X98mOAe4ATh+qd3tc7bqBsAvjsUL2HAjcApwyUXQRctBmPq+jeFOf3j+cpdIH4E2Dvvs5n+7KdBrab15edO1D2nr69o6e4n/cD1wyV/d/+b7d4qN2VwNcHyk7q2/2LKdq9CLgLePRA2VF9/QuH6n4MuHoTf4t5/d9hJfCOgfLJ/freofqnAj8F0i8/e3C/buQ+3thvs2So/J39Ppw/28/1Hf22uSOZg4EbqmrXqtoZeANwRpI9Jiv0RxTvBV5WVXcON9Cv/xTw/+iO4BYBfwfcsZl92CxJ5k9ne5oR/0F3tPw7dEfHP6B7Ix72GGBP4AODhVX1ZboDn2f1RU+mG6V/eGj7cwYXkiwBfgX4QD8tM79//twOfBV45lY+nr+he6Pe0LdzF/C8qlrbn296Ft1j/tnAfQa4cIr7vJvudbM5nglcXFUTkwVVdQ/dKOjg/jU46OMbaee7VbVqYPk7/c/zh+p9B9hn6Hzac5J8PsmNfd/vojsf9Zgp7uc/h5a/Rfc8eES/fARdyLxzI/0EOBL4GnD10D48H3g48Kub2FYzYEtC5usDy1+gO0rZDe59Yz8bOKmqVm6kjQMAqursqrqnqjZU1Weq6vLJCkn2TfKxft71xiSn9uWP7eeKf5zkiiRHDTac5Jp+3vZy4Cf9E23vJB/t27o6yWs387FqhlXVrcC5dFNmLwc+UFVTTbnu3v+8fop1PxhYP3l+5odDdYaX9+x//hvdm+Hg7bfp3qS2xlnAk4AnAntU1eOr6gv9ut3pXjtvnOI+lwK7JRl8Xf6oD4rNsTsb/9uE/vU6YKq60I0qB925ifL5dI9nchrwPLoZjz+iG8U9Cfgm3ahu2Pqh5ckDzsm6DwfW18+n4qeyJ124Dv8t/2OgDc2izT3qfyJwKUB/Yu7/9MuTR0zH0h09vinJm4DTq+pDQ218F7gnyXvpjigvrqp7n7RJ5tEdsX2O7s3mHmAs3ZVqn6R74R5BNzXyiSRjQ4F2LN187A1054Q+STfnfCzdCd8Lk6ysquGjMY2Gf6c7sn0A3T6byuSb0i9Pse6XgfH+98k3z0fQXYjCwPKgG/ufb6AbRQz7hRH5Zrq+qsY3su7HdM/P0+ge8y8YCtgt+V8c69n436b4xTf16f4/Hy+kG738XlXdNVmYZDf681Fb6AZg9yQLNhE0N9Kd9/mLjazf2EGvZsiWjGT+IsktdEczewJHVj/5WVXvq6o9quqw/jYcMFTVLfx87vydwLp0V9dMvvAPBfYGXl9VP6mqn/bTIE8BdgXeWlV3VtXn6MJo+I3on6vquv7J+CRgYVUt67dZ1d/nMZv7h9GMu4Bueutfq+qKjdRZSTcauc9+TPI0uivUJkcLX6N7I3/R0PbD+38lcA3wuKoan+J2OdOsqn4CfInu5PzXp7rfbWj+C8BTkuw3WdAfvL0Y+EY/YmxpZ7qDw3vDK8mzgUduZXufoRuBvWoTdT4NHAh8fyP7cK5+1mq7cb8jmXTXzz8WOLCqrkryQn4+vbBFqupKuhO+9Jcgvh84hS4w9gWuraq7hzbbG7hu6OjuWrpzOoOuG/j9UcDeSQaPnubRvbg1gvopoY2NYO6t04+Uz0jyfrrnzyK6E+3fA97d11uZ5IPAsn7q6RK6CwmeN9ReJfkzupHxTnQhdwPdiOdpdG9c/zSND3PSX9JdUXd+kn+jG3ntAfw6MK+qTtzKdk+me31dkOTNwC3An9JNVT9/Wzu9GT4NnAC8J8m7+/t9I7Bmaxqrqs8n+SjwT/2Vfp8DHkg3PfafVXUR3WN+Md3VgCfTHTjsQhc8v1FVfpxilm3OSOYgurnSVQBV9VHg+3RD461WVd+hu3pm8vMI1wGPnOLE/Vq6zwMM9vWR/OITd3Dofx3dVS8PG7g9pKqeh+a0qjqTbjr11+imQ99GNwp6VlUNXvL8GrqDodfRneA+kO5S2eH2zqN709oFeBfdCeO30U0xfbXRY/g63Wj7RuCf6Y7Y39E/pi9uQ7tr6WYLrqC7ku4jdOdpnl9Vn97Gbm/O/Z8PvBZ4Ot1swyvpzrFNbGq7+3EM3dVwL6C7jPos4HH0U6JVdTPdAcF5wF/T7b+z6D6r9/ltuF9Nk8lLBTdeIXkV8KqqespA2VvpRjYv2Ow76kYuzwc+VFWr+yOTc4AVVfXqflj/dbo3jDfTDbsPoTsKvZJuuusf6Z7An6S79Pk7fdvX9H28sF+eR3cp9YfpXsR30o3GFlTV5AfjJEmNbc5I5mBgeG7608DhSaa6YmRjbqW7OOBrSX4CXAx8G/hfcO90ye/QfW7i+8Bq4MX95dBH0X0Q7QbgX4CXTwbMVAbaOhi4ut/uXXQfbJMkzZD7HclIkrS1/BZmSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZkY+ZJIcmWRlkokkJ06x/uQkl/W37yb58cC6VyT5Xn97xcz2XJI00v8ZM8k84LvA4XT/jvkS4NiqWrGR+n8OPLGqXplkd2AcGAMKuBQ4pKpumpHOS5JGfiRzKDBRVauq6k7gHODoTdQ/Fji7//25wAVVtb4PlguAI5v2VpJ0H/NnuwP3YxFw3cDyauDJU1VM8ihgf+Bzm9h20RTbHQ8cD7DLLrsccuCBB257ryVpB3LppZfeUFULp1o36iGTKco2Nr93DPCRqrpnS7atqjOBMwHGxsZqfHx8a/opSTusJNdubN2oT5etBvYdWN4HWLuRusfw86myLd1WktTAqIfMJcCSJPsn2YkuSJYPV0ryGGA34KsDxecDRyTZLcluwBF9mSRphoz0dFlV3Z1kKV04zAPOqqorkiwDxqtqMnCOBc6pgUvlqmp9krfQBRXAsqpaP5P9l6Qd3UhfwjzTPCcjSVsuyaVVNTbVulGfLpMkzWGGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmDBlJUjOGjCSpGUNGktSMISNJasaQkSQ1Y8hIkpoxZCRJzRgykqRmRj5kkhyZZGWSiSQnbqTOi5KsSHJFkg8OlN+T5LL+tnzmei1JApg/2x3YlCTzgNOAw4HVwCVJllfVioE6S4A3AE+vqpuS7DnQxIaqOnhGOy1Juteoj2QOBSaqalVV3QmcAxw9VOfVwGlVdRNAVf1ohvsoSdqIUQ+ZRcB1A8ur+7JBBwAHJPlKkouTHDmw7sFJxvvyF0x1B0mO7+uMr1u3bnp7L0k7uJGeLgMyRVkNLc8HlgCHAfsAX0pyUFX9GHhkVa1N8mjgc0m+VVVX3aexqjOBMwHGxsaG25YkbYNRH8msBvYdWN4HWDtFnU9U1V1VdTWwki50qKq1/c9VwEXAE1t3WJL0c6MeMpcAS5Lsn2Qn4Bhg+Cqxc4HfBEiyB9302aokuyV50ED504EVSJJmzEhPl1XV3UmWAucD84CzquqKJMuA8apa3q87IskK4B7g9VV1Y5KnAWck+RldmL518Ko0SVJ7qfI0xKSxsbEaHx+f7W5I0pyS5NKqGptq3ahPl0mS5jBDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNTN/tjug+zr11FOZmJiY9nbXrFkDwKJFi6a9bYDFixezdOnSJm3PFa32HbTdf+67jq+9NgyZHcSGDRtmuwvaBu6/uWtH33epqtnuw8gYGxur8fHx2e5GEyeccAIAp5xyyiz3RFvD/Td37Qj7LsmlVTU21TrPyUiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IyXMA/YkkuYW37wroXJvi5evHiWe7JlWnzQbK7tO5ib+6/VhwTn2v6bi/sOtmz/beoSZj+MuZUmJiZY+d3vsfe++812VzbLvAc+CIBbN9w1yz3ZfGuvu6ZJuxMTE3z7ypXsvMdeTdpv4U7mAbBq3S2z3JPNc/sN1zdre2Jigsu+dSX3LNi92X1Mpwfc0R3IXzrxw1nuyeabt2H9tLVlyGyDvffdjz95/Umz3Y3t1ulvP6lZ2zvvsRePe8FrmrW/o7vi3DOatn/Pgt3ZsPh5Te9jR7Zg4rxpa8tzMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc2MfMgkOTLJyiQTSU7cSJ0XJVmR5IokHxwof0WS7/W3V8xcryVJMOKf+E8yDzgNOBxYDVySZHlVrRioswR4A/D0qropyZ59+e7Am4ExoIBL+21vmunHIUk7qlEfyRwKTFTVqqq6EzgHOHqozquB0ybDo6p+1Jc/F7igqtb36y4AjpyhfkuSGP2QWQRcN7C8ui8bdABwQJKvJLk4yZFbsC1Jjk8ynmR83bp109h1SdKoh0ymKBv+3wTzgSXAYcCxwLuSPGwzt6WqzqyqsaoaW7hw4TZ2V5I0aNRDZjWw78DyPsDaKep8oqruqqqrgZV0obM520qSGhr1kLkEWJJk/yQ7AccAy4fqnAv8JkCSPeimz1YB5wNHJNktyW7AEX2ZJGmGjPTVZVV1d5KldOEwDzirqq5IsgwYr6rl/DxMVgD3AK+vqhsBkryFLqgAllXV9P0nHknS/RrpkAGoqvOA84bK3jTwewF/2d+Gtz0LOKt1HyVJUxv16TJJ0hxmyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqxpCRJDVjyEiSmjFkJEnNGDKSpGYMGUlSM4aMJKkZQ0aS1IwhI0lqZuRDJsmRSVYmmUhy4hTrj0uyLsll/e1VA+vuGShfPrM9lyTNn+0ObEqSecBpwOHAauCSJMurasVQ1Q9V1dIpmthQVQe37qckaWqjPpI5FJioqlVVdSdwDnD0LPdJkrSZRj1kFgHXDSyv7suGvTDJ5Uk+kmTfgfIHJxlPcnGSF0x1B0mO7+uMr1u3bhq7Lkka9ZDJFGU1tPxJYL+qejxwIfDegXWPrKox4CXAKUl+5RcaqzqzqsaqamzhwoXT1W9JEqMfMquBwZHJPsDawQpVdWNV3dEvvhM4ZGDd2v7nKuAi4IktOytJuq9RD5lLgCVJ9k+yE3AMcJ+rxJLsNbB4FHBlX75bkgf1v+8BPB0YvmBAktTQSF9dVlV3J1kKnA/MA86qqiuSLAPGq2o58NokRwF3A+uB4/rNHwuckeRndGH61imuSpMkNTTSIQNQVecB5w2VvWng9zcAb5hiu/8Cfq15ByVJGzXq02WSpDnMkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNTPyXyszqtasWcNtP7md099+0mx3Zbu19rpr2HWXnae93TVr1nD7LbdxxblnTHvb6tx+w/WsufPWJm2vWbOGeRtuZsHEefdfWVtl3oYbWbPm7mlpy5GMJKkZRzJbadGiRdy64S7+5PUnzXZXtlunv/0kHrLggdPe7qJFi7hjp1t43AteM+1tq3PFuWewaOFDm7S9aNEifrBhPhsWP69J+4IFE+exaNEjpqUtRzKSpGYcyWyDtdddM2fOydzwox8AsMeevzzLPdl8a6+7hsccsKRJ27ffcP2cOifz05tvBODBv/TwWe7J5rn9huuh0UgGYN6G9XPmnMwD7rgFgJ89qN3fY7rN27AemJ6RjCGzlRYvXjzbXdgiP7yr+w/VLaafWnnMAUua/J3n2r4DmLj5RwA8uuEb97Ra+NBmf+e5tv8mJroLIBYvnp437ZnxiGn7O6eqpqWh7cHY2FiNj4/PdjeaOOGEEwA45ZRTZrkn2hruv7lrR9h3SS6tqrGp1nlORpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUTKpqtvswMsbGxmp8fHxW+3DqqacyMTEx7e1Otrl48eJpb3uy3aVLlzZpe65ote+g7f5z33V87W29JJdW1dhU6+bPdGc0OxYsWDDbXdA2cP/NXTv6vnMkM2AURjKSNNdsaiTjORlJUjOGjCSpGUNGktTMyIdMkiOTrEwykeTEKdYfl2Rdksv626sG1r0iyff62ytmtueSpJG+uizJPOA04HBgNXBJkuVVtWKo6oeqaunQtrsDbwbGgAIu7be9aQa6Lkli9EcyhwITVbWqqu4EzgGO3sxtnwtcUFXr+2C5ADiyUT8lSVMY9ZBZBFw3sLy6Lxv2wiSXJ/lIkn23cFtJUiOjHjKZomz4gz2fBParqscDFwLv3YJtSXJ8kvEk4+vWrdumzkqS7mvUQ2Y1sO/A8j7A2sEKVXVjVd3RL74TOGRzt+23P7OqxqpqbOHChdPWcUnS6IfMJcCSJPsn2Qk4Blg+WCHJXgOLRwFX9r+fDxyRZLckuwFH9GWSpBky0leXVdXdSZbShcM84KyquiLJMmC8qpYDr01yFHA3sB44rt92fZK30AUVwLKqWj/jD0KSdmB+d9kAv7tMkrac310mSZoVhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzhowkqRlDRpLUjCEjSWrGkJEkNWPISJKaMWQkSc0YMpKkZgwZSVIzIx8ySY5MsjLJRJITN1Hv95NUkrF+eb8kG5Jc1t/+deZ6LUkCmD/bHdiUJPOA04DDgdXAJUmWV9WKoXoPAV4LfG2oiauq6uAZ6awk6ReM+kjmUGCiqlZV1Z3AOcDRU9R7C/A24Kcz2TlJ0qaN9EgGWARcN7C8GnjyYIUkTwT2rapPJXnd0Pb7J/kGcAvwt1X1peE7SHI8cHy/eFuSldPW+9GzB3DDbHdCW839N3dt7/vuURtbMeohkynK6t6VyQOAk4Hjpqh3PfDIqroxySHAuUkeV1W33KexqjOBM6evy6MryXhVjc12P7R13H9z146870Z9umw1sO/A8j7A2oHlhwAHARcluQZ4CrA8yVhV3VFVNwJU1aXAVcABM9JrSRIw+iFzCbAkyf5JdgKOAZZPrqyqm6tqj6rar6r2Ay4Gjqqq8SQL+wsHSPJoYAmwauYfgiTtuEZ6uqyq7k6yFDgfmAecVVVXJFkGjFfV8k1s/kxgWZK7gXuAP66q9e17PdJ2iGnB7Zj7b+7aYfddqur+a0mStBVGfbpMkjSHGTKSpGYMme1Ikn2SfCLJ95JcleQdSXZKcliST01R/7eTfCPJN5OsSPKa2ej3jijJPf3XHX07ySeTPKwv3zvJRzayzUWTX5ukmZfktk2s+2aSs4fKnpLka/1+vjLJSX35I5J8auB1d97ANo9L8rkk3+1fx29MMtVHOeYMQ2Y70T8RPwacW1VL6C7X3hX4+43UfyDdycjfqaonAE8ELpqZ3grYUFUHV9VBwHrgzwCqam1V/f7sdk1bIslj6d5Ln5lkl4FV7wWO77/a6iDgw335MuCCqnpCVf0qcGLfzgK6q2ffWlUHAE8Angb86cw8kjYMme3Hs4GfVtW7AarqHuB/Aq8Edp6i/kPori6c/CzRHVW1PX/bwSj7Kt23W0x+seu3+98XJDknyeVJPgQsmNwgyR/1R7sXJXlnklP78oVJPprkkv729Nl4QDuYlwDvAz4DHDVQvifdh8KpqnsGvnNxL7rPANKvu3ygna9U1Wf68tuBpfQhNFcZMtuPxwGXDhb0327wfWDxcOX+cu7lwLVJzk7y0v4bFDSD+s9y/RYDn/8a8CfA7VX1eLoR6SH9NnsDb6T78PHhwIED27wDOLmqngS8EHhXu96r92LgQ8DZwLED5ScDK5N8PMlrkjy4Lz8N+Lckn0/yv/v9CVO/hq8Cdk3y0LYPoR3fVLYfYeArdzajnKp6Fd0b3H8DrwPOatY7DVuQ5DK6keTuwAVT1Hkm8H6492h38oj3UOALVbW+qu4C/mNgm+cAp/ZtLwce2n9LuRpI8iRgXVVdC3wW+PUkuwFU1TJgjG6E8xLg0335+cCjgXfSHSB8I8lCNvFa3UT5yDNkth9X0D2h79Uf/exL95U6U6qqb1XVyXRHxC9s2kMN2tDP1T8K2In+nMwUNnbgsDEPAJ7an+85uKoWVdWt29hXbdyxwIH911pdBTyUgddRVV1VVafTHcw9IcnD+/L1VfXBqnoZ3TebPJOpX8OPBm6by/vQkNl+fBbYOcnL4d5pmH8E3gPcPlw5ya5JDhsoOhi4tn03Naiqbqb7X0iv6y/GGPRF4KUASQ4CHt+X/zfwrCS7JZnPfQ8OPkM3j0+/nf9PqZF+evkPgMcPfLXV0fRTZkmeP3Bl2BK6bx75cZJnJ9m5r/MQ4FfoprU/ADwjyXP6dQuAf6b7NyZzliGznajuqxt+F/iDJN8Dvkv3/3X+pq/yW0lWT97orib7q3T/dfQy4O+Y+tus1VhVfQP4Jt138w06nW4+/nLgr+jChapaA/wD3T/puxBYAdzcb/NaYKy/WGAF8MftH8EOY+eh19AJwJp+f0z6IvCrSfYCXkZ3TuYyugsDXtpfkHMIMN7v168C76qqS6pqA11I/W26fznyLbpRzqkz9ggb8GtlpDkoya5VdVs/kvk43ff6fXy2+yUNcyQjzU0n9UfI3wauBs6d5f5IU3IkI0lqxpGMJKkZQzHgfLsAAAAYSURBVEaS1IwhI0lqxpCRJDVjyEiSmvn/bIQBfx+MrrMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {'OLS':  LinearRegression(),\n",
    "          'Ridge': Ridge(alpha = 5.14587),\n",
    "          'LASSO': Lasso(alpha = 0.01)}\n",
    "\n",
    "scores_df = pd.DataFrame(columns = ['Model', 'Fold', 'Score'])\n",
    "\n",
    "for model_idx, (model_name, model) in enumerate(models.items()):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores = cross_val_score(ridge_model, X_train, y_train, \n",
    "                                 cv=kf, scoring='r2')\n",
    "    for score_idx, score in enumerate(scores):\n",
    "        idx = model_idx*len(scores) + score_idx\n",
    "        scores_df.loc[idx] = [model_name, score_idx, score]\n",
    "\n",
    "plt.figure(figsize=(6,6));\n",
    "sns.boxplot(x='Model', y='Score', data=scores_df, palette='Blues')\n",
    "plt.ylim([0.5, 0.6]);\n",
    "plt.yticks(np.arange(0.45, 0.75, 0.05));\n",
    "plt.ylabel('$R^{2}$ Score', rotation = 0, fontsize = 12, y = 1.05);\n",
    "plt.xlabel(None);\n",
    "plt.title('Model Performance',fontsize = 16, y = 1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the beta coefficients, we first exponential transform the standard deviations of independent variables that were log transformed. <br> \n",
    "We then divide each feature's beta coefficient value by each feature's original standard deviation. <br>\n",
    "Next, we must exponential transform our beta coefficients since we applied a log transform to the dependent variable. <br>\n",
    "\n",
    "The results indicate that: <br>\n",
    "- for every additional time an article is cited, an article increases its Altmetric score by 1.22 <br>\n",
    "- for every additional institution involved, an article increases its Altmetric score by 1.05 <br>\n",
    "- for every additional author that worked on the paper, an article increases its Altmetric score by 1.03 <br>\n",
    "- for every additional reference used, an article increases its Altmetric score by 0.99 <br>\n",
    "- for every additional year since publication, an article increases its Altmetric score by 0.62 <br>\n",
    "\n",
    "The Altmetric score uses the number of citiations as a factor, so its helpful to note that it is the most important factor <br>\n",
    "Obviously, some recommendations are more feasible than others. <br>\n",
    "Using additional references and involving more people is one way to increase article impact, but it may minimize impact from personal contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('num_times_cited', 1.2239503499027489),\n",
       " ('num_institutions', 1.054275226855992),\n",
       " ('num_authors', 1.033348636285743),\n",
       " ('ref_cnt', 0.9947693533855977),\n",
       " ('year', 0.620330061464877)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cols = ['num_times_cited', 'num_institutions', 'num_authors']\n",
    "\n",
    "scales = list(zip(X.columns, scaler.scale_))\n",
    "scales = [np.exp(scale[1]) if scale[0] in log_cols else scale[1] for scale in scales]\n",
    "\n",
    "coefs = list(zip(X.columns, np.exp(lm.coef_/scales)))\n",
    "coefs = sorted(coefs, key=lambda x:x[1], reverse = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [Table of Contents](#table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
